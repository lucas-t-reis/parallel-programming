{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Professional CUDA programming exercises.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucas-t-reis/CUDA/blob/master/notebooks/Professional_CUDA_programming_exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWRgXMDQ6CGr",
        "colab_type": "text"
      },
      "source": [
        "- Checking for Nvidia **CUDA toolkit**\n",
        "- Checking for Nvidia Devices (enabled in Runtime type)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZVpeV9H4jqA",
        "colab_type": "code",
        "outputId": "f16b5175-5bff-4793-fd75-67d41173f30c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!which nvcc\n",
        "!ls -l /dev/nv*"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/cuda/bin/nvcc\n",
            "crw-rw-rw- 1 root root 195,   0 Jan 16 11:33 /dev/nvidia0\n",
            "crw-rw-rw- 1 root root 195, 255 Jan 16 11:33 /dev/nvidiactl\n",
            "crw-rw-rw- 1 root root 247,   0 Jan 16 11:33 /dev/nvidia-uvm\n",
            "crw-rw-rw- 1 root root 247,   1 Jan 16 11:33 /dev/nvidia-uvm-tools\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYfNhHmp6nfu",
        "colab_type": "text"
      },
      "source": [
        "### Installing plugin to allow running CUDA C/C++ - by [andreinechaev](https://github.com/andreinechaev)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RftHNio77-o7",
        "colab_type": "code",
        "outputId": "ed7d3bbb-91e9-46d7-8b44-e3f959255ffb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc_plugin"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-jl9bfupy\n",
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-jl9bfupy\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-cp36-none-any.whl size=4307 sha256=ba46bba5afed64d838bb1aaa23327aa731de6c0a5ae2eab7016e2ca30fdd2374\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-t5ecqg36/wheels/10/c2/05/ca241da37bff77d60d31a9174f988109c61ba989e4d4650516\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n",
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43neWLQD-T8u",
        "colab_type": "text"
      },
      "source": [
        "# Hello World - Example 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSJPGpe6-6oT",
        "colab_type": "code",
        "outputId": "146e0083-09b0-4d66-cfed-c22f18aadc5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "\n",
        "// __global__ qualifier to denote a function called by CPU and executed by GPU    \n",
        "__global__ void helloWorldGPU() {\n",
        "    \n",
        "    int gpu_tid = threadIdx.x;\n",
        "    printf(\"Hello World from GPU thread %d!\\n\", gpu_tid);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    printf(\"Hello World from CPU!\\n\");\n",
        "    \n",
        "    // Kernel\n",
        "    helloWorldGPU <<< 1,10 >>> ();\n",
        "\n",
        "    cudaDeviceReset();\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello World from CPU!\n",
            "Hello World from GPU thread 0!\n",
            "Hello World from GPU thread 1!\n",
            "Hello World from GPU thread 2!\n",
            "Hello World from GPU thread 3!\n",
            "Hello World from GPU thread 4!\n",
            "Hello World from GPU thread 5!\n",
            "Hello World from GPU thread 6!\n",
            "Hello World from GPU thread 7!\n",
            "Hello World from GPU thread 8!\n",
            "Hello World from GPU thread 9!\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVNQOvk7kS8q",
        "colab_type": "text"
      },
      "source": [
        "## Understanting *grid* and *block*\n",
        "(pg.33)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tmpfq5tukdVU",
        "colab_type": "code",
        "outputId": "96487dad-cce2-4180-d567-424709ddfb26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void d_workersData() {\n",
        "    \n",
        "      printf(\"threadIdx(%d, %d, %d) blockIdx(%d, %d, %d) blockDim(%d, %d, %d) gridDim(%d, %d, %d)\\n\",\n",
        "             threadIdx.x,threadIdx.y,threadIdx.z, blockIdx.x,blockIdx.y,blockIdx.z, \n",
        "             blockDim.x,blockDim.y,blockDim.z, gridDim.x,gridDim.y,gridDim.z);  \n",
        "  if(i==0) printf(\"%lf\", d_C[i]);\n",
        "\n",
        "}\n",
        "\n",
        "int main () {\n",
        "    \n",
        "    int n = 6;\n",
        "    dim3 block(3); // Setting each block to have 3 threads\n",
        "    dim3 grid( (n + block.x - 1)/block.x); // Setting x dimension to acomodate 2 blocks (data+threads per block)/blocks in give dimension\n",
        "\n",
        "    // Host check of block and grid dimensions\n",
        "    printf(\"grid.x %d grid.y %d grid.z %d\\n\", grid.x, grid.y, grid.z);\n",
        "    printf(\"block.x %d block.y %d block.z %d\\n\", block.x, block.y, block.z);\n",
        "\n",
        "    d_workersData <<< grid , block >>> ();\n",
        "\n",
        "    cudaDeviceSynchronize(); // Sync CPU and GPU\n",
        "\n",
        "\n",
        "    // Resetting block and grid sizes\n",
        "    block.x = 2;\n",
        "    grid.x = (n + block.x - 1)/(block.x);\n",
        "    printf(\"\\nblock %d grid %d\\n\", block.x, grid.x);\n",
        "\n",
        "    d_workersData <<< grid, block >>> ();\n",
        "\n",
        "    cudaDeviceReset();\n",
        "    \n",
        "    \n",
        "}"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "grid.x 2 grid.y 1 grid.z 1\n",
            "block.x 3 block.y 1 block.z 1\n",
            "threadIdx(0, 0, 0) blockIdx(0, 0, 0) blockDim(3, 1, 1) gridDim(2, 1, 1)\n",
            "threadIdx(1, 0, 0) blockIdx(0, 0, 0) blockDim(3, 1, 1) gridDim(2, 1, 1)\n",
            "threadIdx(2, 0, 0) blockIdx(0, 0, 0) blockDim(3, 1, 1) gridDim(2, 1, 1)\n",
            "threadIdx(0, 0, 0) blockIdx(1, 0, 0) blockDim(3, 1, 1) gridDim(2, 1, 1)\n",
            "threadIdx(1, 0, 0) blockIdx(1, 0, 0) blockDim(3, 1, 1) gridDim(2, 1, 1)\n",
            "threadIdx(2, 0, 0) blockIdx(1, 0, 0) blockDim(3, 1, 1) gridDim(2, 1, 1)\n",
            "\n",
            "block 2 grid 3\n",
            "threadIdx(0, 0, 0) blockIdx(0, 0, 0) blockDim(2, 1, 1) gridDim(3, 1, 1)\n",
            "threadIdx(1, 0, 0) blockIdx(0, 0, 0) blockDim(2, 1, 1) gridDim(3, 1, 1)\n",
            "threadIdx(0, 0, 0) blockIdx(1, 0, 0) blockDim(2, 1, 1) gridDim(3, 1, 1)\n",
            "threadIdx(1, 0, 0) blockIdx(1, 0, 0) blockDim(2, 1, 1) gridDim(3, 1, 1)\n",
            "threadIdx(0, 0, 0) blockIdx(2, 0, 0) blockDim(2, 1, 1) gridDim(3, 1, 1)\n",
            "threadIdx(1, 0, 0) blockIdx(2, 0, 0) blockDim(2, 1, 1) gridDim(3, 1, 1)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRLFonwZVp1i",
        "colab_type": "text"
      },
      "source": [
        "### Observations\n",
        "\n",
        " * Grid dimensions are determined by:\n",
        "    ``` \n",
        "    n = # of elements + threads per block on x\n",
        "    grid.x = (n-1)/(threads per block on x) \n",
        "    ```\n",
        " * Each thread can be uniquely identified by **threadIdx** and **blockIdx**\n",
        " * Host sees block and grid, Device uses pre-initialized **blockDim** and **gridDim**\n",
        " * \\# of executions by changing block capacity or grid capacity respectively:\n",
        "   * ``` work = block (x*y*z)```\n",
        "   * ``` grid (x*y*z) * work``` \n",
        " * Syncing CPU and GPU is something to be aware of when changing properties\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsIUt9lnrW6I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c6e0198e-21c3-4a4b-f58f-952d5af0d78a"
      },
      "source": [
        "%%cu\n",
        "\n",
        "/* Simple array summation using a Kernel */\n",
        "#include <stdio.h>\n",
        "#define N 1024\n",
        "\n",
        "__global__ void d_arraySum(double* d_A, double *d_B, double *d_C) {\n",
        "\t\n",
        "\tint i = threadIdx.x;\n",
        "\td_C[i] = d_A[i] + d_B[i];\n",
        "\n",
        "}\n",
        "\n",
        "__global__ void d_arraySumThreadArithmetic(double* d_A, double *d_B, double *d_C) {\n",
        "    \n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if(i<N) d_C[i] = d_A[i] + d_B[i];\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "void check(double *C) {\n",
        "    \n",
        "    double epsilon = 1.0E-8;\n",
        "    for(int i=0; i<N; i++) \n",
        "      if(C[i] - 2*i > epsilon) {\n",
        "          printf(\"Something went wrong.\\n\");\n",
        "          printf(\"Found %lf expected %d\\n\", C[i], 2*i);\n",
        "          return;\n",
        "      }\n",
        "    \n",
        "    printf(\"Results are ok!\\n\");\n",
        "\n",
        "}\n",
        "\n",
        "int main() {\n",
        "\t\n",
        "  size_t size = N*sizeof(double);\n",
        "  dim3 block(1024);\n",
        "\tdim3 grid(1);\n",
        "\n",
        "  double *A, *B, *C;\n",
        "  A = (double *) malloc(size);\n",
        "  B = (double *) malloc(size);\n",
        "  C = (double *) malloc(size);\n",
        "\n",
        "\tdouble *d_A, *d_B, *d_C;\n",
        "\tcudaMalloc( &d_A, size);\n",
        "  cudaMalloc( &d_B, size);\n",
        "  cudaMalloc( &d_C, size);\n",
        "\n",
        "\tfor(int i=0; i<N; i++) \n",
        "\t\tA[i] = B[i] = (double) i;\n",
        "\n",
        "\tcudaMemcpy(d_A, A, size, cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(d_B, B, size, cudaMemcpyHostToDevice);\n",
        "\tcudaMemset(d_C, 0, size);\n",
        "\n",
        "  // Uncomment the one you want to test. \n",
        "\t//d_arraySum <<< grid,block >>> (d_A, d_B, d_C);\n",
        "  d_arraySumThreadArithmetic <<< 16, 64 >>> (d_A, d_B, d_C);\n",
        "  //d_arraySumThreadArithmetic <<< 64, 16 >>> (d_A, d_B, d_C);\n",
        "  \n",
        "  cudaMemcpy(C, d_C, size, cudaMemcpyDeviceToHost);\n",
        "  cudaDeviceReset();\n",
        "  \n",
        "  check(C);\n",
        "\n",
        "}"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results are ok!\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}